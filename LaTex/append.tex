\appendix
%\addcontentsline{toc}{appendix}{Appendix A}
\chapter{CUDA sample program}
\texttt{
\begin{verbatim}

#include<stdlib.h>
#include<math.h>

/*CUDA kernel to add two matrices*/
__global__ void matAddKernel(int* input1,int* input2,int* output,int size)
{
	int threadX=blockIdx.x*blockDim.x+threadIdx.x;	
	int threadY=blockIdx.y*blockDim.y+threadIdx.y;
	if(threadX<size && threadY<size)	
	{	
		output[threadY*size+threadX]=input1[threadY*size+threadX]+input2[threadY*size+threadX];	
	}
}

int main(int argc,char* argv)
{
	printf("An sample CUDA program \n");
	
	/*Define the input matrix sizes*/
	int matrixSize=100;
	
	/*Host statements */
	/*Allocate memory for matrix hostMatA on host(CPU)*/
	int* hostInMatA=NULL;
	hostInMatA = (int*)malloc(matrixSize*matrixSize*sizeof(int));
	if(hostInMatA==NULL)
	{
		printf("Memory can't be created on host for hostInMat at %d \n",__LINE__);
		return -1;
	}
	
	/*Allocate memory for matrix hostMatB on host(CPU)*/	
	int* hostInMatB=NULL;	
	hostInMatB = (int*)malloc(matrixSize*matrixSize*sizeof(int));	
	if(hostInMatB==NULL)
	{
		printf("Memory can't be created on host for hostInMatB at %d \n",__LINE__);	
		return -1;	
	}
	
	/*Allocate memory for matrix hostOutMat on host(CPU)*/	
	int* hostOutMat=NULL;	
	hostOutMat = (int*)malloc(matrixSize*matrixSize*sizeof(int));	
	if(hostOutMat==NULL)	
	{	
		printf("Memory can't be created on host for hostOutMat at %d \n",__LINE__);		
		return -1;	
	}
	
	/*Allocate memory for matrix hostOutCheck on host(CPU) to check GPU result*/	
	int* hostOutCheck=NULL;	
	hostOutCheck = (int*)malloc(matrixSize*matrixSize*sizeof(int));	
	if(hostOutCheck==NULL)	
	{	
		printf("Memory can't be created on host for hostOutMat at %d \n",__LINE__);		
		return -1;	
	}
	
	/*Generate input source matrices on host*/	
	for(int idx=0;idx<matrixSize*matrixSize;idx++)	
	{
		hostInMatA[idx]=rand()%100;		
		hostInMatB[idx]=rand()%150;	
	}
	
	/*Device statements*/	
	cudaError_t err;	
	/*Allocate memory on device for input and output matrices */	
	/*Allocate device memory for devInMatA*/	
	int* devInMatA;	
	err=cudaMalloc(&devInMatA,matrixSize*matrixSize*sizeof(int));	
	if(err!=cudaSuccess)	
	{	
		printf("Device memory can't be allocated for devInmatA %d \n" ,__LINE__);		
		return -1;	
	}
		
	/*Allocate device memory for devInMatB*/	
	int* devInMatB;	
	err = cudaMalloc(&devInMatB,matrixSize*matrixSize*sizeof(int));	
	if(err!=cudaSuccess)	
	{	
		printf("Device memory can't be allocated for devInmatB %d \n" ,__LINE__);		
		return -1;	
	}
	
	/*Allocate device memory for devOutMat*/	
	int* devOutMat=NULL;	
	err = cudaMalloc(&devOutMat,matrixSize*matrixSize*sizeof(int));	
	if(err!=cudaSuccess)	
	{		
		printf("Device memory can't be allocated for devOutmat %d \n" ,__LINE__);		
		return -1;	
	}
	
	/*Copy matrices from host to devices*/	
	err = cudaMemcpy(devInMatA,hostInMatA,matrixSize*matrixSize*sizeof(int),cudaMemcpyHostToDevice);	
	if(err!=cudaSuccess)	
	{	
		printf("Memory copy failed at %d \n" ,__LINE__);		
		return -1;	
	}	
	err = cudaMemcpy(devInMatB,hostInMatB,matrixSize*matrixSize*sizeof(int),cudaMemcpyHostToDevice);	
	if(err!=cudaSuccess)	
	{	
		printf("Memory copy failed at %d \n" ,__LINE__);		
		return -1;	
	}
	
	/*Kernel parameter initialization*/	
	/*Two dimensional Block size initialization */	
	float BlockSizeX=16.0;	
	float BlockSizeY=16.0;	
	/*Two dimensional grid size initialization */	
	int gridSizeX=ceil(float(matrixSize/BlockSizeX));	
	int gridSizeY=ceil(float(matrixSize/BlockSizeY));	
	
	/*Grid and block initialization*/	
	dim3 block(BlockSizeX,BlockSizeY);	
	dim3 grid(gridSizeX,gridSizeY);
	
	/*Kernel launch*/	
	matAddKernel<<<grid,block>>>(devInMatA,devInMatB,devOutMat,matrixSize);	
	err = cudaGetLastError();	
	if(err!=cudaSuccess)	
	{	
		printf("Kernel Launch failed at %d \n" ,__LINE__);		
		return -1;	
	}
	
	/*Waiting for the GPU to complete its operation*/	
	cudaDeviceSynchronize();	
	
	/*Copy the device result to host */	
	err = cudaMemcpy(hostOutCheck,devOutMat,matrixSize*matrixSize*sizeof(int),cudaMemcpyDeviceToHost);		
	
	/*Check the output from GPU against CPU output*/	
	for(int idx=0;idx<matrixSize*matrixSize;idx++)	
	{	
		hostOutMat[idx]=hostInMatA[idx]+hostInMatB[idx];	
	}
	
	bool check=true;	
	int idx=0;	
	while(check && (idx<matrixSize*matrixSize))	
	{	
		if(!(hostOutMat[idx]==hostOutCheck[idx]))	
		{		
			check=false;		
			break;		
		}	
		idx++;	
	}	
	if(check)	
		printf("Matrix addition completed successfully on GPU");
			
	/*Free the host memory*/	
	if(hostInMatA)	
	{
		free(hostInMatA);	
	}	
	if(hostInMatB)	
	{	
		free(hostInMatB);	
	}	
	if(hostOutMat)	
	{	
		free(hostOutMat);	
	}	
	if(hostOutCheck)	
	{	
		free(hostOutCheck);	
	}
	
	/* Free the device memory*/	
	if(devInMatA)	
	{	
		cudaFree(devInMatA);	
	}	
	if(devInMatB)	
	{	
		cudaFree(devInMatB);	
	}	
	if(devOutMat)	
	{	
		cudaFree(devOutMat);	
	}		
	return 0;
}
\end{verbatim}
}