\chapter{Introduction}
Now a days, there is a lot of research is going in the fields of autonomous drive, image processing and computer vision. In these areas the input is an image or a video. The applications deployed into the autonomous drive field contribute to the decision making capabilities of a machine for driving a vehicle \cite{CUDAscalable}. Whereas, the image processing and computer vision applications include analysis of images, extracting details from images, enhancing the quality of images, etc. \paragraph*{}The decision making in the autonomous drive area has involved in the applications like  object detection, image segmentation, road sign detection, lane detection, pedestrian detection, etc. These applications works on real time images, thus there is a chance of distortion in these images due to bad weather conditions. Some of the cases are fog and noise effect on the images. The images distorted should be restored for analysis to make a good decision. The image restoration might have a very complex approach and requires a considerable amount of time when implemented on a hardware. But, the autonomous drive applications are expected to work in real time, thus it requires to implement those algorithms efficiently by considering the target hardware. In this work, the target hardware for autonomous drive applications is an embedded platform like Tegra X1 SoC and Rcar-H3 SiP. \paragraph*{}The embedded Tegra X1 SoC is equipped with ARM A57 quad MPcore and an NVIDIA GPU with 256 CUDA cores \cite{tegra}. This SoC is lack of application specific modules like image and video decoders, audio processing units, etc. The Rcar-H3 SiP on the other hand has ARM A57 quad MPcore, ARM A53 quad MPcore, PowerVR GPU and many more application specific modules \cite{rcar}. In this work, The Rcar-H3 SiP is used as target hardware for implementing autonomous drive algorithms. The Rcar-H3 SiP has selected because of its richness in application specific modules and powerful ARM big.LITTLE CPU \cite{biglittle}. Two autonomous algorithms namely fog rectification and temporal de-noising are implemented on the Rcar-H3 embedded platform using multi-core CPU programming.\paragraph*{}On the other hand, the computer vision and image processing domain found its applications in the fields of defense, military, entertainment, etc. These applications include image quality enhancement (i.e contrast enhancement, brightness enhancement, de-blurring, de-interlacing, etc)  image analysis, feature extraction etc. These algorithms are implemented on a heterogeneous CPU-GPU platform. A heterogeneous platform contains different kinds of processors like CPU-GPU, CPU-FPGA, etc. FPGA is a programmable hardware, unlike GPU, it can only used for general purpose programming. FPGA is not suitable in these applications, because accuracy issues, FPGA converts floating point operations to fixed point, thus there is a penalty cost in accuracy of the output. \paragraph*{}On the other hand, GPUs are generally used for graphics rendering. Newer GPUs are evolved such that, they can be used for general purpose programming. There are mainly two vendors massively producing GPUs, AMD and NVIDIA. The AMD GPUs are not easily user programmable. However, the NVIDIA GPUs are easily programmable through CUDA(Compute Unified Device Architecture) programming platform. Thus, in this work an NVIDIA GPU is used for maintaining heterogeneous platform. The computer vision, image processing and autonomous algorithms are implemented with performance sensitive code practices on to a CPU-GPU heterogeneous platform.

\section{Motivation}
The computer vision, image processing and autonomous drive algorithms are complex in nature and works on huge data. The algorithm complexity in those areas make them to run slower for normal implementations on a hardware. The slow performance of these algorithms disqualify them to work in real time. Thus, there is a need to implement them efficiently for better performance. \paragraph*{}The hardware is also not uniform for implementing such algorithms. For example image processing and computer vision algorithms run on a stand alone High performance system, whereas autonomous drive algorithms will work on embedded platforms like Rcar-H3 SiP, Tegra-X1 SoC, etc. A common implementation of algorithms to all the platforms is not recommended, since because the hardware resources available are different.\paragraph*{}Thus those algorithms need to be implemented by considering the hardware available. These implementations should ensure the algorithms to run in real time. Hence, these are termed as High performance implementations.

\section{Challenges}
High performance implementations of algorithms are widely used in all the computing areas. It carries a big set of challenges.
\begin{enumerate}
\item  Increased data movement latencies: In case using a Heterogeneous system, the memory copies from host to the device will add considerable amount of latency for the execution. These latencies can be hidden when working with vast amount of data \cite{hpc}. Some of the hardware providers are providing programmable memory hierarchies to avoid data movement latencies. 
\item  Data dependency: The data dependency in algorithms is a cumbersome to solve. The algorithms can not be implemented effectively unless the dependency is resolved. This can be overcome by rewriting the algorithm for the available hardware. One of the cases are, finding a maximum in an array of elements. In the case of maximum, reduction techniques which are optimized for parallel implementation are developed GPU \cite{max}.
\end{enumerate}

\section{Research objectives}
This work has mainly two objectives: a) To develop parallel processing techniques to implement the image processing, computer vision and autonomous algorithms on the target hardware b) Exploit the GPU hardware.
\section{Thesis contribution}
The adaptive contrast enhancement, motion de-blur, fog rectification, temporal denoising and stereo disparity block matching algorithms are implemented with different high performance techniques that ensure them to run in real time. In GPU, shared memory and streams are used for implementing the algorithms. While in CPU, pipelining, multi-core programming are used to enhance the performance of the algorithms.
\begin{enumerate}
\item The algorithms motion de-blur, adaptive contrast enhancement and stereo disparity algorithms are implemented using data parallelism techniques. With the data parallelism techniques, Speed ups in the range 2x to 9x are observed on CPU-GPU heterogeneous platform.

\item Hardware specific features such as different types of memories, streams, Intrinsics are used for implementing the algorithms effectively. Streams based implementation is considered as an advanced future to exploit the GPU hardware resources. GPU kernel tweaking is explained to reduce the hardware resource occupancy.

\item Pipe-lining techniques are used for multi-core CPUs. When there exist a data dependency in the internal modules of the algorithm. With pipelining technique, Speed ups of order 2x to 4x are bserved.
\end{enumerate}
\section{Thesis organization}
This thesis is organised as follows:

\par Chapter 2 presents a brief introduction to high performance computing and mainly focuses on the parallel programming techniques. It also presents a brief introduction about the NVIDIA GPU, CUDA programming model and multi-core processing.

\par Chapter 3 presents the implementations of image processing and computer vision algorithms on NVIDIA GPU. In this chapter adaptive contrast enhancement and motion de-blur algorithms implementation is discussed.

\par Chapter 4 presents the autonomous drive algorithms implementation on embedded platform as well as on CPU-GPU platform. Multi-core implementation of fog rectification and temporal denoising are discussed in this chapter. Stereo disparity block matching algorithm is implemented on CPU-GPU platform which is also presented.

\par Chapter 5 concludes this work by summarizing the high performance techniques used. This chapter also presents the possible future scope of this work.